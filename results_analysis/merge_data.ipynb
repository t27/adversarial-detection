{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('idl_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f727b9d31a81233deed1255550f2d5a36c1210b051c8cf7ad4105ddcebb3e2fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML\n",
    "import io\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_base64(im):\n",
    "    with BytesIO() as buffer:\n",
    "        im.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def image_formatter(im):\n",
    "    return f'<img src=\"data:image/jpeg;base64,{image_base64(im)}\">'\n",
    "\n",
    "def image_formatter2(im):\n",
    "    return f'<img src=\"data:image/jpeg;base64,{im}\">'\n",
    "\n",
    "cifar_class_map = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck',\n",
    "}\n",
    "\n",
    "def label_df(df):\n",
    "    df['actual'] = df['actual'].apply(lambda x:cifar_class_map[x])\n",
    "    df['prediction']=df['prediction'].apply(lambda x:cifar_class_map[x])\n",
    "    return df\n",
    "\n",
    "# HTML(df.to_html(formatters={'image': image_formatter2}, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline1_adv = label_df(pd.read_csv(\"./dev_adv_dataset_results.csv\"))\n",
    "baseline1_adv['adv_detection_result']=np.all(baseline1_adv[['c1','c2','c3','c4']],axis=1)\n",
    "baseline1_real = label_df(pd.read_csv(\"./dev_real_dataset_results.csv\"))\n",
    "baseline1_real['adv_detection_result']=np.all(baseline1_real[['c1','c2','c3','c4']],axis=1)\n",
    "\n",
    "countergan_adv = pd.read_csv(\"./counter_gan_adv_pred.csv\")\n",
    "countergan_real = pd.read_csv(\"./counter_gan_real_pred.csv\")\n",
    "countergan_adv = countergan_adv.drop(['Unnamed: 0'], axis=1)\n",
    "countergan_real = countergan_real.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "defense_gan_real = label_df(pd.read_csv(\"./defensegan_dev_real_dataset_results.csv\"))\n",
    "defense_gan_adv = label_df(pd.read_csv(\"./defensegan_dev_adv_dataset_results.csv\"))"
   ]
  },
  {
   "source": [
    "# Baseline 1 results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adversarial Detection Score: 0.9689562087582484\nFalsely Detected Real Image Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "total_real = len(baseline1_real)\n",
    "total_adv = len(baseline1_adv)\n",
    "adversarial_detection_score = baseline1_adv.adv_detection_result.sum()/total_adv # TP/(TP+FN)since we know all images are adv in baseline1_adv\n",
    "adversarial_false_positives = baseline1_real.adv_detection_result.sum()/total_real #FP/(FP+TN)\n",
    "# (baseline1_adv.actual != baseline1_adv.prediction and baseline1_adv.result).sum()\n",
    "print(\"Adversarial Detection Score:\",adversarial_detection_score)\n",
    "print(\"Falsely Detected Real Image Score:\", adversarial_false_positives)\n",
    "real_html = baseline1_real.to_html(formatters={'image': image_formatter2}, escape=False)\n",
    "adv_html = baseline1_adv.to_html(formatters={'image': image_formatter2}, escape=False)\n",
    "with open(\"baseline1_realimages_visualization.html\",\"w\") as f:\n",
    "    f.write(real_html)\n",
    "with open(\"baseline1_advimages_visualization.html\",\"w\") as f:\n",
    "    f.write(adv_html)"
   ]
  },
  {
   "source": [
    "# Baseline 2(DefenseGAN Results)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adversarial Detection Score: 0.07739038563127311\nFalsely Detected Real Image Score: 0.0808\n"
     ]
    }
   ],
   "source": [
    "total_real = len(defense_gan_real)\n",
    "total_adv = len(defense_gan_adv)\n",
    "adversarial_detection_score = (defense_gan_adv.actual == defense_gan_adv.prediction).sum()/total_adv # TP/(TP+FN)since we know all images are adv in baseline1_adv\n",
    "adversarial_false_positives =  (defense_gan_real.actual == defense_gan_real.prediction).sum()/total_real #FP/(FP+TN)\n",
    "# (baseline1_adv.actual != baseline1_adv.prediction and baseline1_adv.result).sum()\n",
    "print(\"Adversarial Detection Score:\",adversarial_detection_score)\n",
    "print(\"Falsely Detected Real Image Score:\", adversarial_false_positives)\n",
    "real_html = baseline1_real.to_html(formatters={'image': image_formatter2}, escape=False)\n",
    "adv_html = baseline1_adv.to_html(formatters={'image': image_formatter2}, escape=False)\n",
    "with open(\"defensegan_realimages_visualization.html\",\"w\") as f:\n",
    "    f.write(real_html)\n",
    "with open(\"defensegan_advimages_visualization.html\",\"w\") as f:\n",
    "    f.write(adv_html)"
   ]
  },
  {
   "source": [
    "# Counter GAN Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Without Defense:\nClassifier Score on Adv dataset: 0.010323660714285714\nClassifier Score on Real dataset: 0.9221833881578947\n\nWith Defense:\nClassifier Score on Adv dataset with defense: 0.11356026785714286\nClassifier Score on Real dataset with defense: 0.28155838815789475\n"
     ]
    }
   ],
   "source": [
    "countergan_adv.head()\n",
    "total_real = len(countergan_real)\n",
    "total_adv = len(countergan_adv)\n",
    "without_defense_adv_score = (countergan_adv.gt_value == countergan_adv.classifier).sum()/total_adv\n",
    "without_defense_real_score = (countergan_real.gt_value == countergan_real.classifier).sum()/total_real\n",
    "adversarial_detection_score = (countergan_adv.gt_value == countergan_adv.defense_pred).sum()/total_adv # TP/(TP+FN)\n",
    "adversarial_false_positives =  (countergan_real.gt_value == countergan_real.defense_pred).sum()/total_real #FP/(FP+TN)\n",
    "print(\"Without Defense:\")\n",
    "print(\"Classifier Score on Adv dataset:\",without_defense_adv_score)\n",
    "print(\"Classifier Score on Real dataset:\", without_defense_real_score)\n",
    "\n",
    "print(\"\\nWith Defense:\")\n",
    "print(\"Classifier Score on Adv dataset with defense:\",adversarial_detection_score)\n",
    "print(\"Classifier Score on Real dataset with defense:\", adversarial_false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}