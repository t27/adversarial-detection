{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "adversary.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aibYvylFpXAZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoQJChFGpXAm"
      },
      "source": [
        "class AdvDetector(nn.Module):\n",
        "    def __init__(self, in_channels, pooling1=False, pooling2=False):\n",
        "        super(AdvDetector, self).__init__()\n",
        "        \n",
        "        self.pooling1=pooling1\n",
        "        self.pooling2=pooling2\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=in_channels, out_channels=96,kernel_size=3,stride=1, padding=1)\n",
        "        self.layer2=nn.BatchNorm2d(96)\n",
        "        self.layer3=nn.ReLU()\n",
        "        self.layer4=nn.MaxPool2d(2,2) #1st pooling layer\n",
        "        self.layer5=nn.Conv2d(in_channels=96, out_channels=192,kernel_size=3,stride=1,padding=1)\n",
        "        self.layer6=nn.BatchNorm2d(192)\n",
        "        self.layer7=nn.ReLU()\n",
        "        self.layer8=nn.MaxPool2d(2,2)  #2nd pooling layer\n",
        "        self.layer9=nn.Conv2d(in_channels=192, out_channels=192,kernel_size=3,stride=1, padding=1)\n",
        "        self.layer10=nn.BatchNorm2d(192)\n",
        "        self.layer11=nn.ReLU()\n",
        "        self.layer12=nn.Conv2d(in_channels=192,out_channels=2,kernel_size=1,stride=1)\n",
        "        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        \n",
        "    def forward(self,x):        \n",
        "        x = self.conv1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        if self.pooling1==True:\n",
        "            x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.layer7(x)\n",
        "        if self.pooling2==True:\n",
        "            x = self.layer8(x)\n",
        "        x = self.layer9(x)\n",
        "        x = self.layer10(x)\n",
        "        x = self.layer11(x)\n",
        "        x = self.layer12(x)\n",
        "        \n",
        "        x = self.adaptive_avg_pool(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9yaxY3FpXAt",
        "outputId": "e369e1d3-f376-4bbb-c638-1d64e23c2290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "net = AdvDetector(64,False,False)\n",
        "print(net)\n",
        "net.train()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdvDetector(\n",
            "  (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (layer2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer3): ReLU()\n",
            "  (layer4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (layer5): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (layer6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer7): ReLU()\n",
            "  (layer8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (layer9): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (layer10): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer11): ReLU()\n",
            "  (layer12): Conv2d(192, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (adaptive_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdvDetector(\n",
              "  (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (layer2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer3): ReLU()\n",
              "  (layer4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (layer5): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (layer6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer7): ReLU()\n",
              "  (layer8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (layer9): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (layer10): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer11): ReLU()\n",
              "  (layer12): Conv2d(192, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (adaptive_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bptQ92lupXA0",
        "outputId": "8fb65f51-3b24-4521-cefc-047c55ea6e0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "temp_data = np.random.randn(128, 64, 8, 8)\n",
        "temp_data = torch.Tensor(temp_data)\n",
        "out = net(temp_data)\n",
        "out"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-4.4611e-02]],\n",
              "\n",
              "         [[-2.0751e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.7841e-02]],\n",
              "\n",
              "         [[-2.2638e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.1031e-02]],\n",
              "\n",
              "         [[-1.6234e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.8574e-02]],\n",
              "\n",
              "         [[-1.5390e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.8549e-02]],\n",
              "\n",
              "         [[-1.4190e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.1267e-02]],\n",
              "\n",
              "         [[-2.2500e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.4820e-02]],\n",
              "\n",
              "         [[-1.7719e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 6.8073e-02]],\n",
              "\n",
              "         [[-1.1434e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.7589e-02]],\n",
              "\n",
              "         [[-2.1635e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.9847e-02]],\n",
              "\n",
              "         [[-1.2086e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.4997e-02]],\n",
              "\n",
              "         [[-1.7323e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.2124e-02]],\n",
              "\n",
              "         [[-1.9158e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.7102e-02]],\n",
              "\n",
              "         [[-1.7714e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.0317e-02]],\n",
              "\n",
              "         [[-1.6422e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 5.3336e-02]],\n",
              "\n",
              "         [[-1.4293e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.8918e-02]],\n",
              "\n",
              "         [[-1.1982e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 9.5351e-03]],\n",
              "\n",
              "         [[-1.9380e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.5978e-02]],\n",
              "\n",
              "         [[-1.3737e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.0740e-02]],\n",
              "\n",
              "         [[-1.2795e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 9.2451e-02]],\n",
              "\n",
              "         [[-1.6342e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.3640e-02]],\n",
              "\n",
              "         [[-9.2276e-02]]],\n",
              "\n",
              "\n",
              "        [[[-4.7669e-02]],\n",
              "\n",
              "         [[-1.0226e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.7755e-02]],\n",
              "\n",
              "         [[-1.9603e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.4896e-02]],\n",
              "\n",
              "         [[-1.6644e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.4413e-02]],\n",
              "\n",
              "         [[-1.2189e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.3099e-02]],\n",
              "\n",
              "         [[-1.8488e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.2568e-02]],\n",
              "\n",
              "         [[-7.7510e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.1529e-02]],\n",
              "\n",
              "         [[-1.1488e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.3424e-02]],\n",
              "\n",
              "         [[-1.7193e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.2806e-02]],\n",
              "\n",
              "         [[-1.6033e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5130e-02]],\n",
              "\n",
              "         [[-1.7063e-01]]],\n",
              "\n",
              "\n",
              "        [[[-8.9819e-02]],\n",
              "\n",
              "         [[-1.2310e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.4678e-04]],\n",
              "\n",
              "         [[-1.3026e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.8945e-02]],\n",
              "\n",
              "         [[-1.8634e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.0287e-02]],\n",
              "\n",
              "         [[-1.4872e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.0301e-02]],\n",
              "\n",
              "         [[-1.6771e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.4405e-02]],\n",
              "\n",
              "         [[-1.2729e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.4982e-02]],\n",
              "\n",
              "         [[-1.9496e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.8060e-02]],\n",
              "\n",
              "         [[-1.5087e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.9926e-02]],\n",
              "\n",
              "         [[-1.1657e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.7253e-03]],\n",
              "\n",
              "         [[-2.0059e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.4550e-02]],\n",
              "\n",
              "         [[-1.9154e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.4609e-03]],\n",
              "\n",
              "         [[-1.7846e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.0004e-02]],\n",
              "\n",
              "         [[-1.4310e-01]]],\n",
              "\n",
              "\n",
              "        [[[-9.5504e-03]],\n",
              "\n",
              "         [[-1.7302e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5383e-02]],\n",
              "\n",
              "         [[-1.9278e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.7293e-02]],\n",
              "\n",
              "         [[-7.9047e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.1590e-02]],\n",
              "\n",
              "         [[-1.2736e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.7826e-02]],\n",
              "\n",
              "         [[-9.9087e-02]]],\n",
              "\n",
              "\n",
              "        [[[-6.9237e-02]],\n",
              "\n",
              "         [[-1.9783e-01]]],\n",
              "\n",
              "\n",
              "        [[[-8.2157e-03]],\n",
              "\n",
              "         [[-1.6476e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.5430e-02]],\n",
              "\n",
              "         [[-1.3682e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.7120e-02]],\n",
              "\n",
              "         [[-1.3814e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.7653e-02]],\n",
              "\n",
              "         [[-1.0164e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.3492e-03]],\n",
              "\n",
              "         [[-1.6263e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.4167e-04]],\n",
              "\n",
              "         [[-2.0249e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 6.4006e-02]],\n",
              "\n",
              "         [[-2.2975e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.1024e-02]],\n",
              "\n",
              "         [[-1.2154e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.6367e-02]],\n",
              "\n",
              "         [[-2.0166e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.6433e-02]],\n",
              "\n",
              "         [[-1.9239e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 7.0385e-02]],\n",
              "\n",
              "         [[-1.3521e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 8.3142e-04]],\n",
              "\n",
              "         [[-2.1177e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.7679e-02]],\n",
              "\n",
              "         [[-2.1800e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.3353e-02]],\n",
              "\n",
              "         [[-1.3477e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.1731e-02]],\n",
              "\n",
              "         [[-1.5290e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.1775e-02]],\n",
              "\n",
              "         [[-8.1815e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.2726e-02]],\n",
              "\n",
              "         [[-1.9485e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.3400e-02]],\n",
              "\n",
              "         [[-1.0923e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.8602e-02]],\n",
              "\n",
              "         [[-1.3067e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.0043e-02]],\n",
              "\n",
              "         [[-1.5457e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.8650e-02]],\n",
              "\n",
              "         [[-1.9231e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.8512e-02]],\n",
              "\n",
              "         [[-9.5910e-02]]],\n",
              "\n",
              "\n",
              "        [[[-3.7784e-02]],\n",
              "\n",
              "         [[-1.2491e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 9.1219e-03]],\n",
              "\n",
              "         [[-1.5802e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 5.9948e-02]],\n",
              "\n",
              "         [[-1.4172e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.7682e-02]],\n",
              "\n",
              "         [[-1.4794e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.2435e-02]],\n",
              "\n",
              "         [[-1.5823e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.6365e-03]],\n",
              "\n",
              "         [[-1.3153e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.6710e-03]],\n",
              "\n",
              "         [[-1.6877e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.0057e-02]],\n",
              "\n",
              "         [[-1.4711e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.3110e-02]],\n",
              "\n",
              "         [[-1.4637e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.2124e-02]],\n",
              "\n",
              "         [[-1.5979e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 5.1366e-02]],\n",
              "\n",
              "         [[-1.9640e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.2907e-03]],\n",
              "\n",
              "         [[-1.5516e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.5918e-02]],\n",
              "\n",
              "         [[-1.2489e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.0837e-02]],\n",
              "\n",
              "         [[-1.3172e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.3022e-03]],\n",
              "\n",
              "         [[-1.7497e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.8522e-02]],\n",
              "\n",
              "         [[ 1.6676e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.3593e-02]],\n",
              "\n",
              "         [[-1.3736e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9645e-02]],\n",
              "\n",
              "         [[-1.9308e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.1380e-02]],\n",
              "\n",
              "         [[-1.7307e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.7239e-02]],\n",
              "\n",
              "         [[-1.8896e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.5178e-02]],\n",
              "\n",
              "         [[-9.8625e-02]]],\n",
              "\n",
              "\n",
              "        [[[-3.1502e-02]],\n",
              "\n",
              "         [[-1.9599e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.0812e-03]],\n",
              "\n",
              "         [[-8.3221e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.5200e-02]],\n",
              "\n",
              "         [[-1.7243e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.0032e-02]],\n",
              "\n",
              "         [[-1.4181e-01]]],\n",
              "\n",
              "\n",
              "        [[[-8.6537e-03]],\n",
              "\n",
              "         [[-9.7849e-02]]],\n",
              "\n",
              "\n",
              "        [[[-4.9504e-02]],\n",
              "\n",
              "         [[-2.4198e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9299e-02]],\n",
              "\n",
              "         [[-1.0082e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.8737e-02]],\n",
              "\n",
              "         [[-1.1093e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5884e-02]],\n",
              "\n",
              "         [[-1.8512e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.2006e-02]],\n",
              "\n",
              "         [[-2.0869e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.5025e-02]],\n",
              "\n",
              "         [[-1.2693e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.3618e-03]],\n",
              "\n",
              "         [[-1.6504e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.3104e-03]],\n",
              "\n",
              "         [[-2.1273e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.4437e-02]],\n",
              "\n",
              "         [[-1.0579e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.2319e-02]],\n",
              "\n",
              "         [[-2.2284e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.6712e-02]],\n",
              "\n",
              "         [[-1.4482e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.9501e-02]],\n",
              "\n",
              "         [[-8.1758e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 5.9849e-02]],\n",
              "\n",
              "         [[-1.9309e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.4117e-02]],\n",
              "\n",
              "         [[-1.8912e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.8940e-02]],\n",
              "\n",
              "         [[-1.5122e-01]]],\n",
              "\n",
              "\n",
              "        [[[-9.9292e-02]],\n",
              "\n",
              "         [[-1.2785e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.6890e-02]],\n",
              "\n",
              "         [[-2.0074e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.3225e-02]],\n",
              "\n",
              "         [[-1.2106e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.0419e-02]],\n",
              "\n",
              "         [[-1.2760e-01]]],\n",
              "\n",
              "\n",
              "        [[[-4.7180e-02]],\n",
              "\n",
              "         [[-1.6153e-01]]],\n",
              "\n",
              "\n",
              "        [[[-5.3712e-02]],\n",
              "\n",
              "         [[-9.8562e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 3.5660e-02]],\n",
              "\n",
              "         [[-1.8085e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.4137e-02]],\n",
              "\n",
              "         [[-1.7272e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.2636e-02]],\n",
              "\n",
              "         [[-1.1608e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.3112e-02]],\n",
              "\n",
              "         [[-1.8767e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 7.0118e-02]],\n",
              "\n",
              "         [[-1.0037e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.7483e-02]],\n",
              "\n",
              "         [[-1.2587e-01]]],\n",
              "\n",
              "\n",
              "        [[[-6.1978e-02]],\n",
              "\n",
              "         [[-1.9126e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.8418e-02]],\n",
              "\n",
              "         [[-1.6675e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.1571e-02]],\n",
              "\n",
              "         [[-1.2521e-01]]]], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTudelClpXA6",
        "outputId": "518f1bc3-2a50-47cc-93ec-4e0f5c5f93c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(out.shape)\n",
        "out[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 2, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0178]],\n",
              "\n",
              "        [[-0.2264]]], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e2edmY-pXBA",
        "outputId": "b05e541a-2d4d-423c-b084-5bd59f20868d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "target = torch.ones((128))\n",
        "out = out.reshape(128, 2)\n",
        "\n",
        "print(target.shape, out.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128]) torch.Size([128, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yctZsBqZpXBG",
        "outputId": "03b2c31d-bec7-47d9-daf0-92fe72c09824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "out = out.float()\n",
        "\n",
        "loss = criterion(out, target.long())\n",
        "\n",
        "# loss.backward()\n",
        "print(loss)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7708, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOiigL_ApXBN"
      },
      "source": [
        "file=np.load('c1s_train.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVTbD7VepXBT",
        "outputId": "d3b38e5d-a468-495d-ab60-a9107aef330b"
      },
      "source": [
        "print(file)\n",
        "print(file.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[0.02511253 0.         0.         ... 0.14928018 0.14467147\n",
            "    0.15240252]\n",
            "   [0.         0.         0.         ... 0.08861911 0.07271574\n",
            "    0.10648758]\n",
            "   [0.         0.         0.         ... 0.0020269  0.\n",
            "    0.05558911]\n",
            "   ...\n",
            "   [0.17123878 0.12336614 0.09099106 ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.16745529 0.13568199 0.11067381 ... 0.01278207 0.\n",
            "    0.        ]\n",
            "   [0.17070366 0.15572256 0.14748897 ... 0.15146844 0.04827313\n",
            "    0.05673229]]\n",
            "\n",
            "  [[0.00252416 0.12250652 0.19009921 ... 0.22631727 0.21007049\n",
            "    0.20509145]\n",
            "   [0.         0.06003428 0.27195188 ... 0.53127867 0.51131105\n",
            "    0.46020424]\n",
            "   [0.         0.10832304 0.38874257 ... 0.5309818  0.56250304\n",
            "    0.5295518 ]\n",
            "   ...\n",
            "   [0.83916825 0.70556504 0.69942427 ... 0.31367826 0.\n",
            "    0.46911907]\n",
            "   [0.80559593 0.8920938  0.9936337  ... 0.5336421  0.06349538\n",
            "    0.49580386]\n",
            "   [0.70889914 0.8461572  1.0714632  ... 0.7713433  0.24859405\n",
            "    0.45015213]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.18807606 0.24995902 0.21391372 ... 0.00917975 0.01925592\n",
            "    0.07861112]\n",
            "   [0.06362621 0.10074259 0.03351561 ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.0059055  0.00624646 0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.02284142 0.         0.         ... 0.09308422 0.0858413\n",
            "    0.11023966]\n",
            "   [0.23347232 0.15482354 0.17316985 ... 0.09813744 0.08416922\n",
            "    0.11731797]\n",
            "   [0.3507361  0.3326874  0.34127873 ... 0.225755   0.2051584\n",
            "    0.20707513]\n",
            "   ...\n",
            "   [0.13536865 0.19344003 0.20001908 ... 0.15210035 0.3968856\n",
            "    0.33477172]\n",
            "   [0.17228146 0.22663106 0.21727557 ... 0.34836116 0.52053463\n",
            "    0.41770175]\n",
            "   [0.18448819 0.21558991 0.2060293  ... 0.21945477 0.35976645\n",
            "    0.378309  ]]\n",
            "\n",
            "  [[0.27240768 0.34815007 0.33440757 ... 0.2879095  0.28296736\n",
            "    0.30975482]\n",
            "   [0.         0.02712287 0.0369346  ... 0.11724892 0.12219611\n",
            "    0.19980007]\n",
            "   [0.         0.         0.         ... 0.00526032 0.03568016\n",
            "    0.13072315]\n",
            "   ...\n",
            "   [0.06529625 0.         0.         ... 0.         0.\n",
            "    0.06886432]\n",
            "   [0.12290807 0.         0.         ... 0.01109647 0.\n",
            "    0.05158721]\n",
            "   [0.27511698 0.07127272 0.0227673  ... 0.30192795 0.\n",
            "    0.14479373]]]\n",
            "\n",
            "\n",
            " [[[0.20626764 0.15949553 0.12255096 ... 0.05931754 0.05312424\n",
            "    0.10073976]\n",
            "   [0.25141636 0.16523394 0.12061208 ... 0.         0.\n",
            "    0.0283273 ]\n",
            "   [0.24277842 0.19042446 0.17053409 ... 0.         0.\n",
            "    0.01050624]\n",
            "   ...\n",
            "   [0.24904762 0.24896206 0.2062855  ... 0.         0.\n",
            "    0.06222006]\n",
            "   [0.2399303  0.26688862 0.2479581  ... 0.         0.03980216\n",
            "    0.11310238]\n",
            "   [0.20533074 0.22966    0.2124254  ... 0.13966045 0.17608361\n",
            "    0.17789342]]\n",
            "\n",
            "  [[0.0925685  0.         0.06443512 ... 0.07740348 0.09074232\n",
            "    0.17018342]\n",
            "   [0.12502483 0.         0.         ... 0.06709909 0.03256996\n",
            "    0.19331597]\n",
            "   [0.1307709  0.         0.00556285 ... 0.0575732  0.03455004\n",
            "    0.22033846]\n",
            "   ...\n",
            "   [0.2217238  0.         0.         ... 0.3979846  0.29674637\n",
            "    0.41055942]\n",
            "   [0.290893   0.07918807 0.04305375 ... 0.3557791  0.3519328\n",
            "    0.32563248]\n",
            "   [0.41290957 0.33061862 0.25739473 ... 0.2767139  0.26194003\n",
            "    0.18714197]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.27132127 0.17121133 0.12880342 ... 0.11015481 0.1243394\n",
            "    0.18498647]\n",
            "   [0.31353697 0.22839995 0.16464199 ... 0.08065058 0.07942706\n",
            "    0.14116824]\n",
            "   [0.29163626 0.23641735 0.1947057  ... 0.07450473 0.0771811\n",
            "    0.13220531]\n",
            "   ...\n",
            "   [0.20079783 0.17662837 0.20947687 ... 0.1024195  0.10471665\n",
            "    0.15126592]\n",
            "   [0.11831729 0.0791117  0.12706785 ... 0.07674024 0.12133612\n",
            "    0.15246487]\n",
            "   [0.11955567 0.08739254 0.1289121  ... 0.17269653 0.19599597\n",
            "    0.19934915]]\n",
            "\n",
            "  [[0.20767419 0.25795686 0.24581714 ... 0.07786717 0.06037222\n",
            "    0.08892518]\n",
            "   [0.13303511 0.1981015  0.2973488  ... 0.16908601 0.16795538\n",
            "    0.18681432]\n",
            "   [0.13981757 0.16534734 0.21634434 ... 0.1700676  0.18629968\n",
            "    0.20741753]\n",
            "   ...\n",
            "   [0.14670132 0.21851382 0.23992518 ... 0.32700956 0.3362331\n",
            "    0.3015063 ]\n",
            "   [0.13162106 0.15274367 0.14156738 ... 0.5280131  0.4525336\n",
            "    0.34499037]\n",
            "   [0.13897353 0.11900316 0.12264387 ... 0.29095182 0.23297659\n",
            "    0.20215955]]\n",
            "\n",
            "  [[0.5168208  0.3317997  0.25310674 ... 0.2445408  0.24769343\n",
            "    0.2877138 ]\n",
            "   [0.58591676 0.35123444 0.23361664 ... 0.14824615 0.11613955\n",
            "    0.20286354]\n",
            "   [0.5586444  0.4130079  0.31613797 ... 0.12394258 0.07990038\n",
            "    0.19186385]\n",
            "   ...\n",
            "   [0.5301242  0.4075484  0.43567333 ... 0.19665287 0.19808704\n",
            "    0.3469666 ]\n",
            "   [0.42862943 0.3326686  0.4039416  ... 0.21052553 0.3193387\n",
            "    0.4031776 ]\n",
            "   [0.3829473  0.3368849  0.37376451 ... 0.42011386 0.46311486\n",
            "    0.44370845]]]\n",
            "\n",
            "\n",
            " [[[0.3619836  0.42565954 0.42476708 ... 0.42476708 0.42476708\n",
            "    0.3057889 ]\n",
            "   [0.58908314 0.67560434 0.67517245 ... 0.67517245 0.67517245\n",
            "    0.45311916]\n",
            "   [0.5903579  0.6781774  0.6777311  ... 0.6777311  0.6777311\n",
            "    0.45440307]\n",
            "   ...\n",
            "   [0.10268104 0.08526509 0.0671362  ... 0.         0.\n",
            "    0.04465762]\n",
            "   [0.0970752  0.06997462 0.04140522 ... 0.         0.\n",
            "    0.0408967 ]\n",
            "   [0.0924957  0.06119911 0.03718406 ... 0.         0.\n",
            "    0.05328842]]\n",
            "\n",
            "  [[0.323018   0.04587655 0.05108845 ... 0.05108845 0.05108845\n",
            "    0.        ]\n",
            "   [0.72011036 0.14973657 0.15386261 ... 0.15386261 0.15386261\n",
            "    0.        ]\n",
            "   [0.72184    0.15411066 0.1567165  ... 0.1567165  0.1567165\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.00957114 0.01770434 0.         ... 0.01174508 0.00844581\n",
            "    0.16230477]\n",
            "   [0.00526342 0.00737539 0.         ... 0.01640148 0.03846231\n",
            "    0.18535565]\n",
            "   [0.00630115 0.03792606 0.04077631 ... 0.04288654 0.06786006\n",
            "    0.19426183]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.26012933 0.15791743 0.15840021 ... 0.15840021 0.15840021\n",
            "    0.10273939]\n",
            "   [0.34624204 0.2368683  0.23754853 ... 0.23754853 0.23754853\n",
            "    0.184144  ]\n",
            "   [0.34558707 0.23572966 0.23597102 ... 0.23597102 0.23597102\n",
            "    0.18322144]\n",
            "   ...\n",
            "   [0.16184099 0.17428164 0.1795491  ... 0.21854681 0.20621668\n",
            "    0.21310847]\n",
            "   [0.16138496 0.1689128  0.16619065 ... 0.19077812 0.18121757\n",
            "    0.20012885]\n",
            "   [0.1375956  0.12738836 0.11911023 ... 0.11908863 0.11108479\n",
            "    0.13436987]]\n",
            "\n",
            "  [[0.3423214  0.5630503  0.5626116  ... 0.5626116  0.5626116\n",
            "    0.43790764]\n",
            "   [0.04339881 0.1631938  0.16329099 ... 0.16329099 0.16329099\n",
            "    0.13631772]\n",
            "   [0.04287554 0.1610316  0.16081221 ... 0.16081221 0.16081221\n",
            "    0.13436222]\n",
            "   ...\n",
            "   [0.20069532 0.1771919  0.16318615 ... 0.19410136 0.1938635\n",
            "    0.2073367 ]\n",
            "   [0.19084649 0.16806524 0.1681083  ... 0.21901466 0.22491306\n",
            "    0.22778077]\n",
            "   [0.24587676 0.2703352  0.2925427  ... 0.3845362  0.37905398\n",
            "    0.3298074 ]]\n",
            "\n",
            "  [[0.6688777  0.48869652 0.48966154 ... 0.48966154 0.48966154\n",
            "    0.48829016]\n",
            "   [1.0193803  0.7245316  0.72723967 ... 0.72723967 0.72723967\n",
            "    0.6218504 ]\n",
            "   [1.0195998  0.7261128  0.7265953  ... 0.7265953  0.7265953\n",
            "    0.62098646]\n",
            "   ...\n",
            "   [0.2835973  0.2945756  0.2921207  ... 0.25318986 0.24566032\n",
            "    0.29429254]\n",
            "   [0.28105298 0.27399606 0.25265005 ... 0.22112782 0.21689062\n",
            "    0.28398055]\n",
            "   [0.24711083 0.21879204 0.19613516 ... 0.15553738 0.16499294\n",
            "    0.25278264]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.22971277 0.1941344  0.18859005 ... 0.25308046 0.20032172\n",
            "    0.17757379]\n",
            "   [0.24891771 0.22226223 0.20631781 ... 0.32801074 0.23137732\n",
            "    0.2077242 ]\n",
            "   [0.276337   0.27007174 0.24323313 ... 0.34113187 0.19262284\n",
            "    0.15093131]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.06513323 0.02707634 ... 0.         0.\n",
            "    0.21468756]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.23104413]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.07055497]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.72405225 0.9291535  0.9262209  ... 0.41888198 0.49255407\n",
            "    0.41600633]\n",
            "   [0.86799043 1.1563444  1.1636457  ... 0.41106665 0.53490263\n",
            "    0.4933822 ]\n",
            "   [0.77246547 1.0342475  1.0945427  ... 0.31831157 0.390476\n",
            "    0.40815055]\n",
            "   ...\n",
            "   [0.1381392  0.23459537 0.30146283 ... 0.35990292 0.31997585\n",
            "    0.29274696]\n",
            "   [0.2104516  0.33313382 0.39408273 ... 0.38032416 0.32626182\n",
            "    0.30091152]\n",
            "   [0.12498846 0.22805549 0.2837625  ... 0.21902935 0.1748999\n",
            "    0.14406282]]\n",
            "\n",
            "  [[0.17615046 0.20390758 0.20416613 ... 0.41080272 0.29769805\n",
            "    0.26080352]\n",
            "   [0.1391799  0.18076424 0.16448069 ... 0.25483426 0.15994339\n",
            "    0.12524071]\n",
            "   [0.15116927 0.22495781 0.18114024 ... 0.03578893 0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.2903776  0.24247637 0.23035684 ... 0.22000813 0.17815393\n",
            "    0.19357455]\n",
            "   [0.23993424 0.19227012 0.21129048 ... 0.24741681 0.2312612\n",
            "    0.24059089]\n",
            "   [0.37656048 0.39046243 0.3682528  ... 0.4841978  0.5259522\n",
            "    0.4850756 ]]\n",
            "\n",
            "  [[0.7949151  0.8295982  0.81818986 ... 0.5341724  0.60263085\n",
            "    0.54395735]\n",
            "   [0.85930926 0.842127   0.8227354  ... 0.49915466 0.61532867\n",
            "    0.53862995]\n",
            "   [0.86204183 0.80108297 0.81464577 ... 0.5703929  0.5198714\n",
            "    0.38184318]\n",
            "   ...\n",
            "   [0.07048053 0.24403368 0.3066817  ... 0.27866104 0.24846376\n",
            "    0.25263834]\n",
            "   [0.16126917 0.32916266 0.4041931  ... 0.27465922 0.22428231\n",
            "    0.24982235]\n",
            "   [0.07951829 0.2524158  0.3108623  ... 0.13430616 0.06301212\n",
            "    0.135331  ]]]\n",
            "\n",
            "\n",
            " [[[0.3086194  0.33736375 0.3345836  ... 0.30698076 0.3038651\n",
            "    0.24220756]\n",
            "   [0.4622511  0.5039427  0.49917722 ... 0.4372933  0.43030664\n",
            "    0.3183037 ]\n",
            "   [0.4786836  0.53011185 0.52493656 ... 0.43322632 0.4262227\n",
            "    0.31524196]\n",
            "   ...\n",
            "   [0.3676339  0.39891872 0.24429467 ... 0.15785582 0.28419834\n",
            "    0.24505131]\n",
            "   [0.35082832 0.3768718  0.2783588  ... 0.27333093 0.30228052\n",
            "    0.23850995]\n",
            "   [0.32135206 0.3295509  0.27209932 ... 0.3357664  0.33493507\n",
            "    0.26341063]]\n",
            "\n",
            "  [[0.18918633 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.31237307 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.35866487 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.5142699  0.2088091  0.         ... 0.45781302 0.44108933\n",
            "    0.10169906]\n",
            "   [0.5147236  0.228994   0.12787312 ... 0.22853257 0.23809785\n",
            "    0.08405361]\n",
            "   [0.54615694 0.25480214 0.23586802 ... 0.27837485 0.26690188\n",
            "    0.1058775 ]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.37811735 0.36627164 0.36850005 ... 0.37889266 0.3761766\n",
            "    0.29619431]\n",
            "   [0.45851648 0.44816336 0.45014402 ... 0.47783932 0.47383282\n",
            "    0.3788322 ]\n",
            "   [0.42184356 0.38654506 0.38839856 ... 0.44792864 0.45244\n",
            "    0.36429447]\n",
            "   ...\n",
            "   [0.17089017 0.07081654 0.03352661 ... 0.0668745  0.1279759\n",
            "    0.12180784]\n",
            "   [0.15067494 0.03636391 0.02226328 ... 0.05961077 0.06055539\n",
            "    0.0701816 ]\n",
            "   [0.23565684 0.15785126 0.12149783 ... 0.19439553 0.19288848\n",
            "    0.1885905 ]]\n",
            "\n",
            "  [[0.2797771  0.42432368 0.41835967 ... 0.37112087 0.36669174\n",
            "    0.31057128]\n",
            "   [0.10230067 0.20337623 0.20134385 ... 0.15815859 0.15929122\n",
            "    0.15734881]\n",
            "   [0.12379041 0.2495529  0.2461063  ... 0.18323897 0.18074551\n",
            "    0.1711063 ]\n",
            "   ...\n",
            "   [0.09795912 0.14558986 0.19552748 ... 0.45644408 0.24717328\n",
            "    0.16525625]\n",
            "   [0.1034821  0.14406726 0.17109644 ... 0.3528916  0.29831946\n",
            "    0.2393773 ]\n",
            "   [0.02643617 0.01872935 0.06815511 ... 0.03847231 0.04333276\n",
            "    0.07480994]]\n",
            "\n",
            "  [[0.7128299  0.62079215 0.62201285 ... 0.61450684 0.61006767\n",
            "    0.5568313 ]\n",
            "   [0.9553145  0.774402   0.7761369  ... 0.7580614  0.74848527\n",
            "    0.6333575 ]\n",
            "   [0.9482613  0.7448357  0.7477388  ... 0.73069626 0.7298487\n",
            "    0.6246987 ]\n",
            "   ...\n",
            "   [0.62878853 0.429013   0.28799984 ... 0.36064476 0.4929876\n",
            "    0.4028737 ]\n",
            "   [0.5904949  0.37525186 0.28715482 ... 0.36084783 0.36962202\n",
            "    0.35897458]\n",
            "   [0.63864684 0.46952796 0.385642   ... 0.52372867 0.5211756\n",
            "    0.4716389 ]]]\n",
            "\n",
            "\n",
            " [[[0.33925033 0.3943139  0.39698344 ... 0.36728442 0.36463964\n",
            "    0.2761575 ]\n",
            "   [0.5266809  0.6120268  0.61744183 ... 0.5660213  0.5562908\n",
            "    0.38650954]\n",
            "   [0.4771659  0.5792136  0.5960975  ... 0.56249094 0.54390824\n",
            "    0.36811006]\n",
            "   ...\n",
            "   [0.19341213 0.18866292 0.16805424 ... 0.5416572  0.60253596\n",
            "    0.42517385]\n",
            "   [0.17370678 0.15935929 0.14180025 ... 0.46269512 0.5027674\n",
            "    0.37484142]\n",
            "   [0.14614746 0.13251773 0.12368257 ... 0.35456628 0.37454906\n",
            "    0.29078168]]\n",
            "\n",
            "  [[0.3105377  0.08260696 0.06812693 ... 0.08968854 0.0788222\n",
            "    0.        ]\n",
            "   [0.61838675 0.18136133 0.10951524 ... 0.14387363 0.13324392\n",
            "    0.        ]\n",
            "   [0.6277827  0.25321266 0.09822583 ... 0.171074   0.13548163\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.26059604 0.1842891  0.18975787 ... 0.31994256 0.26836762\n",
            "    0.        ]\n",
            "   [0.22811106 0.15542594 0.16367273 ... 0.25619897 0.27128282\n",
            "    0.01659622]\n",
            "   [0.17094415 0.18049346 0.19520175 ... 0.18405429 0.20458268\n",
            "    0.07642584]]\n",
            "\n",
            "  [[0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   ...\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.28919083 0.22105028 0.21978359 ... 0.22879076 0.21969838\n",
            "    0.16753544]\n",
            "   [0.3628529  0.3126889  0.30549726 ... 0.31622228 0.30238315\n",
            "    0.23948774]\n",
            "   [0.36493176 0.37202486 0.3630036  ... 0.32180187 0.30786487\n",
            "    0.22955497]\n",
            "   ...\n",
            "   [0.15830861 0.12245326 0.12052624 ... 0.26677215 0.27801958\n",
            "    0.22704633]\n",
            "   [0.16607055 0.14139831 0.13266164 ... 0.22270721 0.26705095\n",
            "    0.25781822]\n",
            "   [0.1483629  0.13224281 0.12907198 ... 0.2551583  0.25938272\n",
            "    0.25625038]]\n",
            "\n",
            "  [[0.3167041  0.48952058 0.51403356 ... 0.48038393 0.46867234\n",
            "    0.37854508]\n",
            "   [0.05418429 0.11477344 0.15652594 ... 0.15995923 0.14529331\n",
            "    0.13972603]\n",
            "   [0.         0.         0.         ... 0.11679191 0.14542438\n",
            "    0.15366542]\n",
            "   ...\n",
            "   [0.15627265 0.15705848 0.16002992 ... 0.06247541 0.00975655\n",
            "    0.02740716]\n",
            "   [0.14578527 0.14170393 0.15900531 ... 0.02829327 0.\n",
            "    0.        ]\n",
            "   [0.1980356  0.20777917 0.22107825 ... 0.         0.\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.65720516 0.55705047 0.5413155  ... 0.5331283  0.5389388\n",
            "    0.5021072 ]\n",
            "   [0.94207484 0.804726   0.76180434 ... 0.75588375 0.7513348\n",
            "    0.5938788 ]\n",
            "   [0.9469325  0.9318544  0.8732616  ... 0.77345455 0.7304495\n",
            "    0.56612754]\n",
            "   ...\n",
            "   [0.4170885  0.3530076  0.3324192  ... 0.7424493  0.77498925\n",
            "    0.64053863]\n",
            "   [0.3988091  0.34325805 0.32614765 ... 0.62404305 0.695389\n",
            "    0.6179653 ]\n",
            "   [0.33550996 0.30641788 0.30179945 ... 0.6026379  0.61578345\n",
            "    0.5323756 ]]]]\n",
            "(50000, 16, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZXHObwApXBZ"
      },
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                 # else \"cpu\")\n",
        "device=\"cpu\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj2Z8K92pXBf"
      },
      "source": [
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 10\n",
        "train_losses, test_losses = [], []"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMKaQy9OpXBq"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kehcx9AGqLv4"
      },
      "source": [
        "X_train=temp_data \n",
        "y_train=target"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE3k1J3hqMBU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n93nZ7ibpXB1"
      },
      "source": [
        "## train data\n",
        "class trainData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "train_data = trainData(torch.FloatTensor(X_train), \n",
        "                       torch.FloatTensor(y_train))\n",
        "## test data    \n",
        "class testData(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "    \n",
        "\n",
        "#test_data = testData(torch.FloatTensor(X_test))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynzSSaohqzTs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NUj1umuqqXg"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=4, shuffle=True)\n",
        "#test_loader = DataLoader(dataset=test_data, batch_size=1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9s-sagyp54x"
      },
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSW_mac1rX2a"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlF_d8mfrFtt",
        "outputId": "dd1a30fa-2e80-45f2-f491-2031eae27fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "# train\n",
        "EPOCHS=20\n",
        "net.train()\n",
        "for e in range(1, EPOCHS+1):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = net(X_batch)\n",
        "        \n",
        "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "        acc = accuracy(y_pred, y_batch.unsqueeze(1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "\n",
        "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-756897041394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 962\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;31m# dim == 3 or dim > 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75HK-EyHukNG"
      },
      "source": [
        "y_pred_list = []\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for X_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_test_pred = net(X_batch)\n",
        "        y_test_pred = torch.sigmoid(y_test_pred)\n",
        "        y_pred_tag = torch.round(y_test_pred)\n",
        "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}